{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start Guide\n",
    "\n",
    "This guide shows you how to set up and use *scarlet2* to model a hyperspectral image cube. We assume that you have a full installation of _scarlet2_ including `optax`, `numpyro`, and `h5py`. We'll see below where these packages are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages and setup\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scarlet2 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "We load an example data set (here an image cube from HSC with 5 bands) *and* a detection catalog. If such a catalog is not available, packages like [SEP](http://sep.readthedocs.io/) and [photutils](https://photutils.readthedocs.io/en/stable/) will happily generate one.\n",
    "\n",
    "To make tests like this one convenient, we have a separate package `scarlet-test-data`, which will automatically be (pip-)installed with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scarlet2.utils import import_scarlet_test_data\n",
    "import_scarlet_test_data()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then you can load the data set:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scarlet_test_data import data_path\n",
    "\n",
    "file = jnp.load(os.path.join(data_path, \"hsc_cosmos_35.npz\"))\n",
    "data = jnp.asarray(file[\"images\"])\n",
    "channels = list(file['filters'])\n",
    "centers = jnp.array([(src['y'], src['x']) for src in file[\"catalog\"]]) # Note: y/x convention!\n",
    "weights = jnp.asarray(1/file[\"variance\"])\n",
    "psf = jnp.asarray(file[\"psfs\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "```{warning}\n",
    "\n",
    "Coordinates in *scarlet* are given in the C/numpy notation (y,x) as opposed to the more conventional (x,y) ordering.\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model Frame and Observation\n",
    "\n",
    "A `Frame` in _scarlet2_ is a description of the hyperspectral cube of the model or the observations. Think of it as the metadata, what aspects of the sky are described here. At the least, a `Frame` holds the `shape` of the cube, for which we use the convention `(C, H, W)` for the number of elements in 3 dimensions: `C` for the number of bands/channels and `H/W` for the height and width of the images.\n",
    "\n",
    "An `Observation` combines a `Frame` with several data units, similar to header-data arrangement in FITS files. In addition to the actual science image cube, you can and often must provide weights for all elements in the data cube, an image cube of the PSF model (one image for all or one for each channel), an `astropy.WCS` structure to translate from pixel to sky coordinates, and labels for all channels. The reason for specifying them is to enable the code to internally map from the model frame, in which you seek to fit a model, to the observed data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "```{note}\n",
    "It is critical to realize that there are two frames: one for model that represents the scene on the sky, and one\n",
    " for any observation of that scene. The frames may be identical, but usually they are not, in which case the\n",
    "observation is a degraded version of the model. The degradation could be in terms of spatial resolution, PSF\n",
    "blurring, spectral coverage, or all of the above. Choosing model frame and the observation frame as the same\n",
    "implies that no information has been lost by degradation.\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this example, we assume that bands and pixel locations are identical between the model and the observation. Because we have ground-based images, the degradation comes from the PSF. With different PSFs in each band, we need to provide a reference PSF for the model. We simply choose a minimal Gaussian PSF that is barely well-sampled (standard deviation of 0.7 pixels) as our reference kernel:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_psf = GaussianPSF(0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this we can fully specify the `Frame` and `Observation`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_frame = Frame(Box(data.shape), psf=model_psf, channels=channels)\n",
    "\n",
    "obs = Observation(data,\n",
    "                  weights,\n",
    "                  psf=ArrayPSF(psf),\n",
    "                  channels=channels,\n",
    "                  ).match(model_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last command calls the `match` method to compute, e.g., PSF difference kernels and resampling transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Display Image Cube\n",
    "\n",
    "We can now make use of the plotting function `plot.observation` to create a RGB image of our data.\n",
    "We're going to use a $\\mathrm{sinh}^{-1}$ function, which is automatically tuned to reveal both the noise level and the highlights, to normalize the flux in each filter to create a color-consistent RGB image."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "norm = plot.AsinhAutomaticNorm(obs)\n",
    "plot.observation(obs, norm=norm, sky_coords=centers, show_psf=True, add_labels=True)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we use no `wcs` in this `Observation`, all coordinates are already in image pixels, otherwise RA/Dec pairs are expected as `astropy` sky coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Sources\n",
    "\n",
    "You now need to define sources that are going to be fit. The full model, which we will call `Scene`, is a collection of `Source`s. Each source contains at least one `Component`, and each of those is defined by a `center`, `spectrum`, and `morphology`, and each of these are models with their own parameters. You can have as many sources in a scene, or as many components in a source, as you want. To represent stars or other point sources, we provide the class `PointSource`, which adopts the PSF of the model frame as the morphological model of the source.\n",
    "\n",
    "To adding sources to a scene is easy. You create the scene (as a python context with the `with` keyword) and then create a source inside of that context. It will automatically be added to the overall scene model. But now we have to decide what the initial values of `spectrum` and `morphology` should be. You can choose them as you see fit, but we also provide convenience methods. For instance `init.pixel_spectrum` takes the spectrum of one pixel (typically the center pixel), and `init.from_gaussian_moments` measures the spectrum and morphology by measuring the 2nd moments and creating an elliptical Gaussian to match those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Scene(model_frame) as scene:\n",
    "    for center in centers:\n",
    "        try:\n",
    "            spectrum, morph = init.from_gaussian_moments(obs, center, min_corr=0.99)\n",
    "        except ValueError:\n",
    "            spectrum = init.pixel_spectrum(obs, center)\n",
    "            morph = init.compact_morphology()\n",
    "\n",
    "        Source(center, spectrum, morph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we know something about the scene, we might want to customize the modeling. Let's assume that we know that object 0 is a star. We could just replace that source with a `PointSource`, but for clarity we rebuild the entire source list, making one change for source 0 and accepting everything else from the default initialization above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with Scene(model_frame) as scene:\n",
    "    for i, center in enumerate(centers):\n",
    "        if i == 0: # we know source 0 is a star\n",
    "            spectrum = init.pixel_spectrum(obs, center)\n",
    "            PointSource(center, spectrum)\n",
    "        else:\n",
    "            try:\n",
    "                spectrum, morph = init.from_gaussian_moments(obs, center, min_corr=0.99)\n",
    "            except ValueError:\n",
    "                spectrum = init.pixel_spectrum(obs, center)\n",
    "                morph = init.compact_morphology()\n",
    "\n",
    "            Source(center, spectrum, morph)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can now check what source we have in `scene`:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(scene.sources)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the first source is indeed a `PointSource`, while all others are standard `Source`s. The data portions in these models are listed as, e.g., `f32[31,31]`, which denotes an image array of 31x31 pixels. The size of these boxes was determined by `init.from_gaussian_moments` to contain most of the flux (or the largest box that seems to be occuoied by only one source)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Model\n",
    "\n",
    "The `Scene` class holds the list of sources, create a model of the sky, which determines the likelihood of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scene_array = scene() # evaluate the model\n",
    "print(\"Initial likelihood:\",obs.log_likelihood(scene_array))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can now write your own fitter or sampler, but we provide the machinery for that as well. We're using `optax` for the optimization. First we need to define which parameters of the model should be optimized. This includes stepsizes and, optionally, differentiable constraints from `numpyro`:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from numpyro.distributions import constraints\n",
    "spec_step = partial(relative_step, factor=0.05) # best set size of spectrum parameters\n",
    "\n",
    "parameters = scene.make_parameters()\n",
    "for i in range(len(scene.sources)):\n",
    "    parameters += Parameter(scene.sources[i].spectrum.data,\n",
    "                            name=f\"spectrum:{i}\",\n",
    "                            constraint=constraints.positive,\n",
    "                            stepsize=spec_step)\n",
    "    if i == 0:\n",
    "        parameters += Parameter(scene.sources[i].center,\n",
    "                                name=f\"center:{i}\",\n",
    "                                stepsize=0.1)\n",
    "    else:\n",
    "        parameters += Parameter(scene.sources[i].morphology.data,\n",
    "                                name=f\"morph:{i}\",\n",
    "                                constraint=constraints.positive,\n",
    "                                stepsize=0.1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A model parameter that is not listed in `parameters` will not be updated. Now we can run the fitting method, and update every one of the `parameters`. We give ourselves a head-start by first running a linear solver for the spectra given the shapes of every source:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxiter = 200\n",
    "scene.set_spectra_to_match(obs, parameters)\n",
    "scene_ = scene.fit(obs, parameters, max_iter=maxiter, e_rel=1e-4, progress_bar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interact with Results\n",
    "\n",
    "The updated source models are now available in `scene_`. We can evaluate the entire scene and compute the now improved likelihood:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scene_array = scene_()\n",
    "print(\"Optimized likelihood:\",obs.log_likelihood(scene_array))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Display Full Scene"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot.scene(scene_,\n",
    "           obs,\n",
    "           norm=norm,\n",
    "           show_model=True,\n",
    "           show_rendered=True,\n",
    "           show_observed=True,\n",
    "           show_residual=True,\n",
    "           add_boxes=True,\n",
    "           )\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The fit is overall quite good, with low residuals, but it's not perfect. Let's investigate..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Access All Sources\n",
    "\n",
    "Individual sources can be accessed and evaluated as well, but we have to decide in which frame we want to see them. There are three options:\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get models for source 1\n",
    "source = scene_.sources[1]\n",
    "# in its own source box (indicated by the white boxes in the figure above)\n",
    "source_array = source()\n",
    "# inserted in model frame\n",
    "source_in_scene_array = scene_.evaluate_source(source)\n",
    "# as it appears in observed frame\n",
    "source_as_seen = obs.render(source_in_scene_array)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10,4))\n",
    "axes[0].imshow(plot.img_to_rgb(source_array, norm=norm))\n",
    "axes[1].imshow(plot.img_to_rgb(source_in_scene_array, norm=norm))\n",
    "axes[2].imshow(plot.img_to_rgb(source_as_seen, norm=norm))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We also provide a function to create all of these source images:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot.sources(scene_,\n",
    "             norm=norm,\n",
    "             observation=obs,\n",
    "             show_model=True,\n",
    "             show_rendered=True,\n",
    "             show_observed=True,\n",
    "             show_spectrum=True,\n",
    "             add_markers=False,\n",
    "             add_boxes=True,\n",
    ")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that each source \"lives\" in a smaller box and is then placed into the larger scene. The model of object 0 assumes the simple Gaussian shape of the model PSF, which is the internal representation of a point source.\n",
    "\n",
    "It's noticeable that all other sources, however, show pixel patterns that don't seem right. Some of them follow other sources (especially source 2) or noise (sources 4-6). What we see here is the limitation of non-parametric models: they can fit anything, but the likelihood may not have enough information to constrain all of these degrees of freedom. More/stronger constraints or priors can help, and we will describe their use in [a separate tutorial](howto/priors).\n",
    "\n",
    "### Source Measurements\n",
    "\n",
    "As shown above, source models are generated in the model frame (which is the best-fit representation of the full hyperspectral `Frame`), from which any measurement can directly be made without having to deal with noise, PSF convolution, overlapping sources, etc.\n",
    "\n",
    "For instance, the color information in these plots stems from the spectrum, i.e. the per-band amplitude, which are computed from the hyperspectral model by integrating over the morphology. The source spectra plots in the right panels above have done exactly that. The convention of these fluxes is given by the units and ordering of the original data cube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"----------------- {}\".format(channels))\n",
    "for k, src in enumerate(scene_.sources):\n",
    "    print (\"Source {}, Fluxes: {}\".format(k, measure.flux(src)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other measurements (e.g. `centroid`) or `Moments` are also implemented:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "g = measure.Moments(scene_.sources[1])\n",
    "print(\"Source 1 ellipticity:\", g.ellipticity)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "All of these measurements are ordered by channel, so the ellipticity above is listed as `[[e1_g, e1_r, e1_i, e1_z, e1_y],[e2_g, e2_r, e2_i, e2_z, e2_y]]`. That they are all the same should not come as a surprise: For single-component models, there is no variation of the morphology across the channels."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and Re-Use Model\n",
    "\n",
    "To preserve the model for posterity, individual sources (or their sub-models) or entire scenes can be serialized into a HDF5 file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scarlet2.io\n",
    "\n",
    "id = 35\n",
    "filename = \"hsc_cosmos.h5\"\n",
    "scarlet2.io.model_to_h5(scene_, filename, id=id, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stored model be loaded in the same way. Every source can be utilized as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene__ = scarlet2.io.model_from_h5(filename, id=id)\n",
    "plot.scene(scene__, observation=obs, norm=norm, add_boxes=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now add two more sources to account for the largest residuals we have seen above. As we don't know their location accurately, we allow the fitter to shift/recenter the sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter the context of the scene to create new elements\n",
    "with scene__:\n",
    "    # add two marginally detected sources at their approximate locations\n",
    "    yx = [(14., 44.), (42., 9.), centers[1]]\n",
    "    for center in yx:\n",
    "        center = jnp.array(center)\n",
    "        spectrum = init.pixel_spectrum(obs, center)\n",
    "        morph = init.compact_morphology()\n",
    "        Source(center, spectrum, morph)\n",
    "\n",
    "# need to remake the parameter structure because we have more free parameters now\n",
    "parameters__ = scene__.make_parameters()\n",
    "for i in range(len(scene__.sources)):\n",
    "    parameters__ += Parameter(scene__.sources[i].spectrum.data,\n",
    "                              name=f\"spectrum:{i}\",\n",
    "                              constraint=constraints.positive,\n",
    "                              stepsize=spec_step)\n",
    "    if i == 0:\n",
    "        parameters__ += Parameter(scene__.sources[i].center,\n",
    "                                  name=f\"center:{i}\",\n",
    "                                  stepsize=0.1)\n",
    "    else:\n",
    "        parameters__ += Parameter(scene__.sources[i].morphology.data,\n",
    "                                  name=f\"morph:{i}\",\n",
    "                                  constraint=constraints.positive,\n",
    "                                  stepsize=0.1)\n",
    "\n",
    "scene___ = scene__.fit(obs, parameters__, max_iter=maxiter, e_rel=1e-4, progress_bar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the log-likelihood is slightly better than before. Let's have a look at the new model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.scene(scene___,\n",
    "           obs,\n",
    "           norm=norm,\n",
    "           show_model=True,\n",
    "           show_rendered=True,\n",
    "           show_observed=True,\n",
    "           show_residual=True,\n",
    "           add_boxes=True\n",
    "           )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the two new sources 7 and 8, and that most of the other features are very similar to before. As expected, the residuals have visibly improved where we added the source and are now dominated by a red-blue pattern in the center of source 1, which we should probably fit with 2 components."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
