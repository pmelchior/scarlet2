{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e00bde47-7577-427e-a0bb-3b4f6b5923ac",
   "metadata": {},
   "source": [
    "# Fit Multiple Observations\n",
    "\n",
    "This tutorial shows how to model sources from images observed in different ways, which could mean images taken with the same instrument but different pointings and PSFs, or with different instruments. For this guide we will use a multi-band observation from the Hyper-Suprime Cam (HSC) and a single high-resolution image from the Hubble Space Telescope (HST)."
   ]
  },
  {
   "cell_type": "code",
   "id": "28eb2f83-3250-4222-ab9c-bfcfa4bab2ff",
   "metadata": {
    "id": "28eb2f83-3250-4222-ab9c-bfcfa4bab2ff"
   },
   "source": [
    "import astropy.io.fits as fits\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "# Import Packages and setup\n",
    "import numpy as np\n",
    "from astropy.wcs import WCS\n",
    "\n",
    "import scarlet2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f3bebc3f-e085-456d-b22a-843755b2524a",
   "metadata": {
    "id": "f3bebc3f-e085-456d-b22a-843755b2524a"
   },
   "source": [
    "## Load Data\n",
    "\n",
    "We first load the HSC and HST images, channel names, and PSFs. For the images, we need to swap the byte order if necessary because a bug in astropy does not respect the local endianness… We also don’t have precomputed weight/variance maps, so we will need to compute them afterwards."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Installing data package if not already installed\n",
    "from scarlet2.utils import import_scarlet_test_data\n",
    "\n",
    "import_scarlet_test_data()\n",
    "from scarlet_test_data import data_path\n",
    "import os\n",
    "\n",
    "# Load the HSC image data\n",
    "obs_hdu = fits.open(os.path.join(data_path, \"test_resampling\", \"Cut_HSC1.fits\"))\n",
    "data_hsc = obs_hdu[0].data.astype('float32')\n",
    "wcs_hsc = WCS(obs_hdu[0].header)\n",
    "channels_hsc = ['g', 'r', 'i', 'z', 'y']\n",
    "\n",
    "# Load the HSC PSF data\n",
    "psf_hsc_data = fits.open(os.path.join(data_path, \"test_resampling\", \"PSF_HSC.fits\"))[0].data.astype('float32')\n",
    "psf_hsc = scarlet2.ArrayPSF(psf_hsc_data)\n",
    "\n",
    "# Load the HST image data\n",
    "hst_hdu = fits.open(os.path.join(data_path, \"test_resampling\", \"Cut_HST1.fits\"))\n",
    "data_hst = hst_hdu[0].data.astype('float32')\n",
    "wcs_hst = WCS(hst_hdu[0].header)\n",
    "channels_hst = ['F814W']\n",
    "\n",
    "# Load the HST PSF data\n",
    "psf_hst = fits.open(os.path.join(data_path, \"test_resampling\", \"PSF_HST.fits\"))[0].data.astype('float32')\n",
    "psf_hst = psf_hst[None, :, :]\n",
    "psf_hst = scarlet2.ArrayPSF(psf_hst)\n",
    "\n",
    "# Scale the HST data\n",
    "data_hst = data_hst[None, ...].astype('float32')\n",
    "data_hst *= data_hsc.max() / data_hst.max()"
   ],
   "id": "d6a3d0653b15f720",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Next we have to create a source catalog for the images. We’ll use `sep` for that, but any other detection method will do. Since HST is higher resolution and less affected by blending, we use it for detection but we also run detection on the HSC image to calculate the background RMS:",
   "id": "8921c8d15a2b7576"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import sep\n",
    "from scarlet2 import Starlet\n",
    "\n",
    "\n",
    "def makeCatalog(data_lr, data_hr, lvl=3, wave=True):\n",
    "    # Create a catalog of detected source by running SEP on the wavelet transform\n",
    "    # of the sum of the high resolution images and the low resolution images interpolated \n",
    "    # to the high resolution grid\n",
    "\n",
    "    coords_in = jnp.stack(jnp.meshgrid(jnp.linspace(0, 1, data_lr.shape[-1] + 2)[1:-1],\n",
    "                                       jnp.linspace(0, 1, data_lr.shape[-2] + 2)[1:-1]), -1)\n",
    "\n",
    "    coords_out = jnp.stack(jnp.meshgrid(jnp.linspace(0, 1, data_hr.shape[-2] + 2)[1:-1],\n",
    "                                        jnp.linspace(0, 1, data_hr.shape[-2] + 2)[1:-1]), -1)\n",
    "\n",
    "    interp_im = jax.vmap(scarlet2.interpolation.resample2d,\n",
    "                         in_axes=(0, None, None))(data_lr, coords_in, coords_out)\n",
    "\n",
    "    # Normalisation\n",
    "    interp_im = interp_im / jnp.sum(interp_im, axis=(1, 2))[:, None, None]\n",
    "    hr_images = data_hr / jnp.sum(data_hr, axis=(1, 2))[:, None, None]\n",
    "\n",
    "    # Summation to create a detection image\n",
    "    detect_image = jnp.sum(interp_im, axis=0) + jnp.sum(hr_images, axis=0)\n",
    "    # Rescaling to HR image flux\n",
    "    detect_image *= jnp.sum(data_hr)\n",
    "    # Wavelet transform\n",
    "    wave_detect = Starlet.from_image(detect_image).coefficients\n",
    "\n",
    "    if wave:\n",
    "        # Creates detection from the first 3 wavelet levels\n",
    "        detect = wave_detect[:lvl, :, :].sum(axis=0)\n",
    "    else:\n",
    "        detect = detect_image\n",
    "\n",
    "    # Runs SEP detection\n",
    "    bkg = sep.Background(np.array(detect))\n",
    "    catalog = sep.extract(np.array(detect), 3, err=bkg.globalrms)\n",
    "    bg_rms = []\n",
    "    for img in [np.array(data_lr), np.array(data_hr)]:\n",
    "        if np.size(img.shape) == 3:\n",
    "            bg_rms.append(np.array([sep.Background(band).globalrms for band in img]))\n",
    "        else:\n",
    "            bg_rms.append(sep.Background(img).globalrms)\n",
    "\n",
    "    return catalog, bg_rms, detect_image"
   ],
   "id": "3fb078fc808243e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Making catalog.\n",
    "# With the wavelet option on, only the first 3 wavelet levels are used for detection. Set to 1 for better detection\n",
    "wave = 1\n",
    "lvl = 3\n",
    "catalog_hst, (bg_hsc, bg_hst), detect = makeCatalog(data_hsc, data_hst, lvl, wave)\n",
    "\n",
    "# we can now set the empirical noise rms for both observations\n",
    "obs_hst_weights = np.ones(data_hst.shape) / (bg_hst ** 2)[:, None, None]\n",
    "obs_hsc_weights = np.ones(data_hsc.shape) / (bg_hsc ** 2)[:, None, None]"
   ],
   "id": "1657f82abe0cac42",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "09b36cbc-15f9-4805-a06f-bb4049f163ea",
   "metadata": {},
   "source": [
    "## Create Frame and Observations\n",
    "\n",
    "We have two different instruments with different pixel resolutions, so we need two different observations. Since the HST image is at a much higher resolution, we define our model `Frame` to use the HST PSF and the HST resolution. The high resolution and low resolution `Observation` are then matched to the model frame, to define the renderering operation. "
   ]
  },
  {
   "cell_type": "code",
   "id": "82c4a070",
   "metadata": {
    "id": "82c4a070"
   },
   "source": [
    "obs_hst = scarlet2.Observation(data_hst,\n",
    "                               wcs=wcs_hst,\n",
    "                               psf=psf_hst,\n",
    "                               channels=channels_hst,\n",
    "                               weights=obs_hst_weights)\n",
    "\n",
    "obs_hsc = scarlet2.Observation(data_hsc,\n",
    "                               wcs=wcs_hsc,\n",
    "                               psf=psf_hsc,\n",
    "                               channels=channels_hsc,\n",
    "                               weights=obs_hsc_weights)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "17c8b119-497d-4be0-b75c-c514a72836cc",
   "metadata": {},
   "source": "Define the model frame by the union (or intersection) of the observation frames"
  },
  {
   "cell_type": "code",
   "id": "b0f316c6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "b0f316c6",
    "outputId": "020b1350-1c74-46f7-9d02-9003de27b113"
   },
   "source": [
    "model_frame = scarlet2.Frame.from_observations(\n",
    "    observations=[obs_hst, obs_hsc],\n",
    "    coverage=\"union\"  # or \"intersection\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "abb5bbf9-0eb7-4c37-bb55-43904ec6af48",
   "metadata": {
    "id": "abb5bbf9-0eb7-4c37-bb55-43904ec6af48"
   },
   "source": "Finally we can visualize the detections for the multi-band HSC and single-band HST images in their native resolutions:"
  },
  {
   "cell_type": "code",
   "id": "95a0833d",
   "metadata": {
    "id": "95a0833d"
   },
   "source": [
    "norm_hst = scarlet2.plot.AsinhAutomaticNorm(obs_hst)\n",
    "norm_hsc = scarlet2.plot.AsinhAutomaticNorm(obs_hsc)\n",
    "\n",
    "pixel_hst = np.stack((catalog_hst['y'], catalog_hst['x']), axis=1)\n",
    "# Convert the HST pixel coordinates to sky coordinates\n",
    "ra_dec = obs_hst.frame.get_sky_coord(pixel_hst)\n",
    "# Convert to HSC pixel\n",
    "pixel_hsc = obs_hsc.frame.get_pixel(ra_dec)\n",
    "\n",
    "scarlet2.plot.observation(obs_hst, norm=norm_hst, sky_coords=pixel_hst, show_psf=True);\n",
    "scarlet2.plot.observation(obs_hsc, norm=norm_hsc, sky_coords=pixel_hsc, show_psf=True);"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initialize sources from multiple observations",
   "id": "e6709450d1d6e677"
  },
  {
   "cell_type": "code",
   "id": "31c326b5-a5ca-494b-9bf7-706e3ede149b",
   "metadata": {},
   "source": [
    "import scarlet2.init as init\n",
    "\n",
    "with scarlet2.Scene(model_frame) as scene:\n",
    "    for i, center in enumerate(ra_dec):\n",
    "        try:\n",
    "            spectrum, morph = init.from_gaussian_moments([obs_hst, obs_hsc], center, min_corr=0.99)\n",
    "        except ValueError:\n",
    "            spectrum = init.pixel_spectrum([obs_hst, obs_hsc], center)\n",
    "            morph = init.compact_morphology()\n",
    "        scarlet2.Source(center, spectrum, morph)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "scarlet2.plot.scene(scene,\n",
    "                    observation=obs_hsc,\n",
    "                    show_rendered=True,\n",
    "                    show_observed=True,\n",
    "                    show_residual=True,\n",
    "                    norm=norm_hsc);\n",
    "scarlet2.plot.scene(scene,\n",
    "                    observation=obs_hst,\n",
    "                    show_rendered=True,\n",
    "                    show_observed=True,\n",
    "                    show_residual=True,\n",
    "                    norm=norm_hst,\n",
    "                    label_kwargs={'color': 'red'});"
   ],
   "id": "9df20ea2790196a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Fit with multiple observations",
   "id": "5765f3385e73e562"
  },
  {
   "cell_type": "markdown",
   "id": "6rQcrodX0g3V",
   "metadata": {
    "id": "6rQcrodX0g3V"
   },
   "source": "The definition of the parameters does not change:"
  },
  {
   "cell_type": "code",
   "id": "8e1ae1b6",
   "metadata": {
    "id": "8e1ae1b6"
   },
   "source": [
    "from numpyro.distributions import constraints\n",
    "from functools import partial\n",
    "from scarlet2.module import relative_step\n",
    "\n",
    "spec_step = partial(relative_step, factor=0.05)\n",
    "morph_step = partial(relative_step, factor=1e-3)\n",
    "\n",
    "parameters = scene.make_parameters()\n",
    "for i in range(len(scene.sources)):\n",
    "    parameters += scarlet2.Parameter(scene.sources[i].spectrum,\n",
    "                                     name=f\"spectrum.{i}\",\n",
    "                                     constraint=constraints.positive,\n",
    "                                     stepsize=spec_step)\n",
    "    parameters += scarlet2.Parameter(scene.sources[i].morphology,\n",
    "                                     name=f\"morph.{i}\",\n",
    "                                     constraint=constraints.unit_interval,\n",
    "                                     stepsize=morph_step)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " But the inital linear solver for the spectrum amplitudes and the fitting method receive lists of observations now:",
   "id": "81bb89a6412b8ce8"
  },
  {
   "cell_type": "code",
   "id": "iwq3MApn0CEx",
   "metadata": {
    "id": "iwq3MApn0CEx"
   },
   "source": [
    "scene.set_spectra_to_match([obs_hsc, obs_hst], parameters)\n",
    "scene_ = scene.fit([obs_hsc, obs_hst], parameters, max_iter=200, progress_bar=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cea96264-b30f-47ae-a4e6-5957eccf573d",
   "metadata": {},
   "source": "The result of this operation is a much more accurate model for both observations (although it could use a few more iterations):"
  },
  {
   "cell_type": "code",
   "id": "940018a8-ca51-440e-8b54-bfb425e4a2c7",
   "metadata": {},
   "source": [
    "scarlet2.plot.scene(scene_,\n",
    "                    observation=obs_hsc,\n",
    "                    show_rendered=True,\n",
    "                    show_observed=True,\n",
    "                    show_residual=True,\n",
    "                    add_labels=True,\n",
    "                    add_boxes=True,\n",
    "                    norm=norm_hsc);\n",
    "scarlet2.plot.scene(scene_,\n",
    "                    observation=obs_hst,\n",
    "                    show_rendered=True,\n",
    "                    show_observed=True,\n",
    "                    show_residual=True,\n",
    "                    add_labels=True,\n",
    "                    add_boxes=True,\n",
    "                    norm=norm_hst,\n",
    "                    box_kwargs={'edgecolor': 'red', 'facecolor': 'none'},\n",
    "                    label_kwargs={'color': 'red'});"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
