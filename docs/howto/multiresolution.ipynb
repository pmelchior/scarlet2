{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e00bde47-7577-427e-a0bb-3b4f6b5923ac",
   "metadata": {},
   "source": [
    "# Model sources with multi-resolution observations\n",
    "\n",
    "This tutorial shows how to model sources frome images observed with different telescopes. We will use a multiband observation with the Hyper-Sprime Cam (HSC) and a single high-resolution image from the Hubble Space Telescope (HST)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28eb2f83-3250-4222-ab9c-bfcfa4bab2ff",
   "metadata": {
    "id": "28eb2f83-3250-4222-ab9c-bfcfa4bab2ff"
   },
   "outputs": [],
   "source": [
    "# Import Packages and setup\n",
    "import numpy as np\n",
    "import astropy.io.fits as fits\n",
    "from astropy.wcs import WCS\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# use a better colormap and don't interpolate the pixels\n",
    "matplotlib.rc('image', cmap='gray', interpolation='none', origin='lower')\n",
    "\n",
    "import scarlet2\n",
    "from scarlet2 import plot\n",
    "from astropy.visualization.lupton_rgb import AsinhMapping\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bebc3f-e085-456d-b22a-843755b2524a",
   "metadata": {
    "id": "f3bebc3f-e085-456d-b22a-843755b2524a"
   },
   "source": [
    "## Load Data\n",
    "\n",
    "We first load the HSC and HST images, channel names, and PSFs. For the images, we need to swap the byte order if necessary because a bug in astropy does not respect the local endianness… We also don’t have precomputed weight/variance maps, so we will need to compute them afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a919d88-201e-4ad2-9bcc-01289ae527e2",
   "metadata": {
    "id": "2a919d88-201e-4ad2-9bcc-01289ae527e2"
   },
   "outputs": [],
   "source": [
    "# Installing data package if not already installed\n",
    "from scarlet2.utils import import_scarlet_test_data\n",
    "import_scarlet_test_data()\n",
    "from scarlet_test_data import data_path\n",
    "import os\n",
    "\n",
    "# Load the HSC image data\n",
    "obs_hdu = fits.open(os.path.join(data_path, \"test_resampling\", \"Cut_HSC1.fits\"))\n",
    "data_hsc = obs_hdu[0].data.astype('float32')\n",
    "wcs_hsc = WCS(obs_hdu[0].header)\n",
    "channels_hsc = ['g','r','i','z','y']\n",
    "\n",
    "# Load the HSC PSF data\n",
    "psf_hsc_data  = fits.open(os.path.join(data_path, \"test_resampling\", \"PSF_HSC.fits\"))[0].data.astype('float32')\n",
    "psf_hsc = scarlet2.ArrayPSF(psf_hsc_data)\n",
    "\n",
    "# Load the HST image data\n",
    "hst_hdu = fits.open(os.path.join(data_path, \"test_resampling\", \"Cut_HST1.fits\"))\n",
    "data_hst = hst_hdu[0].data.astype('float32')\n",
    "wcs_hst = WCS(hst_hdu[0].header)\n",
    "channels_hst = ['F814W']\n",
    "\n",
    "# Load the HST PSF data\n",
    "psf_hst = fits.open(os.path.join(data_path, \"test_resampling\", \"PSF_HST.fits\"))[0].data.astype('float32')\n",
    "psf_hst = psf_hst[None,:,:]\n",
    "psf_hst = scarlet2.ArrayPSF(psf_hst)\n",
    "\n",
    "# Scale the HST data\n",
    "data_hst = data_hst[None, ...].astype('float32')\n",
    "data_hst *= data_hsc.max() / data_hst.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a142cae8-8a3d-4d80-88e1-4fa1d5e1e440",
   "metadata": {},
   "source": [
    "Next we have to create a source catalog for the images. We’ll use `sep` for that, but any other detection method will do. Since HST is higher resolution and less affected by blending, we use it for detection but we also run detection on the HSC image to calculate the background RMS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff21267-1eea-4c7e-b3cd-0c208ffd63a1",
   "metadata": {
    "id": "3ff21267-1eea-4c7e-b3cd-0c208ffd63a1"
   },
   "outputs": [],
   "source": [
    "import sep\n",
    "from scarlet2 import Starlet\n",
    "\n",
    "def makeCatalog(data_lr, data_hr, lvl = 3, wave = True):\n",
    "    # Create a catalog of detected source by running SEP on the wavelet transform\n",
    "    # of the sum of the high resolution images and the low resolution images interpolated \n",
    "    # to the high resolution grid\n",
    "    \n",
    "    coords_in = jnp.stack(jnp.meshgrid(jnp.linspace(0,1, data_lr.shape[-1]+2)[1:-1],\n",
    "                                jnp.linspace(0,1, data_lr.shape[-2]+2)[1:-1]), -1)\n",
    "\n",
    "    coords_out = jnp.stack(jnp.meshgrid(jnp.linspace(0,1, data_hr.shape[-2]+2)[1:-1],\n",
    "                                        jnp.linspace(0,1, data_hr.shape[-2]+2)[1:-1]), -1)\n",
    "\n",
    "    interp_im = jax.vmap(scarlet2.interpolation.resample2d, \n",
    "                      in_axes=(0,None,None))(data_lr, coords_in, coords_out)\n",
    "\n",
    "    # Normalisation\n",
    "    interp_im = interp_im/jnp.sum(interp_im, axis = (1,2))[:,None, None]\n",
    "    hr_images = data_hr/jnp.sum(data_hr, axis = (1,2))[:,None, None]\n",
    "\n",
    "    # Summation to create a detection image\n",
    "    detect_image = jnp.sum(interp_im, axis = 0) + jnp.sum(hr_images, axis = 0)\n",
    "    # Rescaling to HR image flux\n",
    "    detect_image *= jnp.sum(data_hr)\n",
    "    # Wavelet transform\n",
    "    wave_detect = Starlet.from_image(detect_image).coefficients\n",
    "\n",
    "    if wave:\n",
    "        # Creates detection from the first 3 wavelet levels\n",
    "        detect = wave_detect[:lvl,:,:].sum(axis = 0)\n",
    "    else:\n",
    "        detect = detect_image\n",
    "\n",
    "    # Runs SEP detection\n",
    "    bkg = sep.Background(np.array(detect))\n",
    "    catalog = sep.extract(np.array(detect), 3, err=bkg.globalrms)\n",
    "    bg_rms = []\n",
    "    for img in [np.array(data_lr), np.array(data_hr)]:\n",
    "        if np.size(img.shape) == 3:\n",
    "            bg_rms.append(np.array([sep.Background(band).globalrms for band in img]))\n",
    "        else:\n",
    "            bg_rms.append(sep.Background(img).globalrms)\n",
    "\n",
    "    return catalog, bg_rms, detect_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a692b52a",
   "metadata": {
    "id": "a692b52a"
   },
   "outputs": [],
   "source": [
    "# Making catalog.\n",
    "# With the wavelet option on, only the first 3 wavelet levels are used for detection. Set to 1 for better detection\n",
    "wave = 1\n",
    "lvl = 3\n",
    "catalog_hst, (bg_hsc, bg_hst), detect = makeCatalog(data_hsc, data_hst, lvl, wave)\n",
    "\n",
    "# we can now set the empirical noise rms for both observations\n",
    "obs_hst_weights = np.ones(data_hst.shape) / (bg_hst**2)[:, None, None]\n",
    "obs_hsc_weights = np.ones(data_hsc.shape) / (bg_hsc**2)[:, None, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fab5f3e-7fec-40d1-9c14-52f814b77e2d",
   "metadata": {},
   "source": [
    "## Create Frame and Observations\n",
    "\n",
    "We have two different instruments with different pixel resolutions, so we need two different observations. Since the HST image is at a much higher resolution, we define our model `Frame` to use the HST PSF and the HST resolution. The high resolution and low resolution `Observation` are then matched to the model frame, to define the renderering operation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f17c5e",
   "metadata": {
    "id": "87f17c5e"
   },
   "outputs": [],
   "source": [
    "obs_hst = scarlet2.Observation(data_hst,\n",
    "                               wcs=wcs_hst,\n",
    "                               psf=psf_hst,\n",
    "                               channels=channels_hst,\n",
    "                               weights=obs_hst_weights)\n",
    "\n",
    "obs_hsc = scarlet2.Observation(data_hsc,\n",
    "                               wcs=wcs_hsc,\n",
    "                               psf=psf_hsc,\n",
    "                               channels=channels_hsc,\n",
    "                               weights=obs_hsc_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b36cbc-15f9-4805-a06f-bb4049f163ea",
   "metadata": {},
   "source": [
    "Define the model frame by the union (or intersection) of the observation frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c4a070",
   "metadata": {
    "id": "82c4a070"
   },
   "outputs": [],
   "source": [
    "model_frame = scarlet2.Frame.from_observations(\n",
    "    observations = [obs_hst, obs_hsc], \n",
    "    coverage = \"union\" # or \"intersection\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c8b119-497d-4be0-b75c-c514a72836cc",
   "metadata": {},
   "source": [
    "Finally we can visualize the detections for the multi-band HSC and single-band HST images in their native resolutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f316c6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "b0f316c6",
    "outputId": "020b1350-1c74-46f7-9d02-9003de27b113"
   },
   "outputs": [],
   "source": [
    "norm_hst = AsinhMapping(minimum=-1, stretch=5, Q=3)\n",
    "norm_hsc = AsinhMapping(minimum=-1, stretch=5, Q=3)\n",
    "\n",
    "pixel_hst = np.stack((catalog_hst['y'], catalog_hst['x']), axis=1)\n",
    "# Convert the HST pixel coordinates to sky coordinates\n",
    "ra_dec = obs_hst.frame.get_sky_coord(pixel_hst)\n",
    "# Convert to HSC pixel\n",
    "pixel_hsc = obs_hsc.frame.get_pixel(ra_dec)\n",
    "\n",
    "plot.observation(obs_hst, norm=norm_hst, sky_coords=pixel_hst, show_psf=True);\n",
    "plot.observation(obs_hsc, norm=norm_hsc, sky_coords=pixel_hsc, show_psf=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb5bbf9-0eb7-4c37-bb55-43904ec6af48",
   "metadata": {
    "id": "abb5bbf9-0eb7-4c37-bb55-43904ec6af48"
   },
   "source": [
    "## Initialize sources from multiple observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a0833d",
   "metadata": {
    "id": "95a0833d"
   },
   "outputs": [],
   "source": [
    "from scarlet2.scene import Scene\n",
    "from scarlet2 import init\n",
    "from scarlet2.source import Source\n",
    "from scarlet2.module import Parameter\n",
    "\n",
    "from numpyro.distributions import constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nU57epS6w5Lj",
   "metadata": {
    "id": "nU57epS6w5Lj"
   },
   "outputs": [],
   "source": [
    "with Scene(model_frame) as scene:\n",
    "    for i, center in enumerate(ra_dec):\n",
    "        try:\n",
    "            spectrum, morph = init.from_gaussian_moments([obs_hst, obs_hsc], center, min_corr=0.99)\n",
    "        except ValueError:\n",
    "            spectrum = init.pixel_spectrum([obs_hst, obs_hsc], center)\n",
    "            morph = init.compact_morphology()\n",
    "        Source(\n",
    "            center,\n",
    "            spectrum,\n",
    "            morph\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d5b1cd-7d65-42f0-99fe-ce4898ff034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scarlet2.plot.scene(scene, observation=obs_hsc, show_rendered=True, show_observed=True, show_residual=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c326b5-a5ca-494b-9bf7-706e3ede149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scarlet2.plot.scene(scene, observation=obs_hst, show_rendered=True, show_observed=True, show_residual=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43ad351-7e15-4fd5-a3c1-4361f621ab74",
   "metadata": {},
   "source": [
    "Initialize sources parameters with their constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe88d83",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0fe88d83",
    "outputId": "c1517e5b-7852-4ce0-9c97-f267710310ca"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from scarlet2.module import relative_step\n",
    "spec_step = partial(relative_step, factor=0.05)\n",
    "\n",
    "parameters = scene.make_parameters()\n",
    "for i in range(len(scene.sources)):\n",
    "    parameters += Parameter(scene.sources[i].spectrum, name=f\"spectrum.{i}\", constraint=constraints.positive, stepsize=spec_step)\n",
    "    parameters += Parameter(scene.sources[i].morphology, name=f\"morph.{i}\", constraint=constraints.positive, stepsize=0.1)\n",
    "\n",
    "scene.set_spectra_to_match([obs_hsc, obs_hst], parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6rQcrodX0g3V",
   "metadata": {
    "id": "6rQcrodX0g3V"
   },
   "source": [
    "## Fit with multiple observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1ae1b6",
   "metadata": {
    "id": "8e1ae1b6"
   },
   "outputs": [],
   "source": [
    "scene_ = scene.fit([obs_hsc, obs_hst], parameters, max_iter=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f9b0cf-8266-4ce2-83c3-7d682729e0cb",
   "metadata": {},
   "source": [
    "Show scene in HSC frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iwq3MApn0CEx",
   "metadata": {
    "id": "iwq3MApn0CEx"
   },
   "outputs": [],
   "source": [
    "scarlet2.plot.scene(scene_, observation=obs_hsc, show_rendered=True, show_observed=True, show_residual=True, add_labels=True, add_boxes=True, norm=norm_hsc);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea96264-b30f-47ae-a4e6-5957eccf573d",
   "metadata": {},
   "source": [
    "Show scene in HST frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940018a8-ca51-440e-8b54-bfb425e4a2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scarlet2.plot.scene(scene_, observation=obs_hst, show_rendered=True, show_observed=True, show_residual=True, add_labels=True, add_boxes=True, norm=norm_hst);"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "galsim",
   "language": "python",
   "name": "galsim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
