{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Neural Priors\n",
    "\n",
    "In [the sampling tutorial](sampling), we have demonstrated how to define parameters with priors.\n",
    "This guide shows you how to set up and use neural network priors.\n",
    "We make use of the related package [`galaxygrad`](https://github.com/SampsonML/galaxygrad), which can be pip-installed.\n",
    "\n",
    "This guide will follow the [Quick Start Guide](../0-quickstart), with changes in the initialization and parameter specification. We assume that you have a full installation of _scarlet2_ including `optax`, `numpyro`, `h5py` and `galaxygrad`.\n",
    "\n",
    "More details about the use of a score-based prior model for diffusion can be found in the paper [\"Score-matching neural networks for improved multi-band source separation\", Sampson et al., 2024, A&C, 49, 100875](http://ui.adsabs.harvard.edu/abs/2024A&C....4900875S)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages and setup\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scarlet2 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Observation\n",
    "\n",
    "Again we import the test data and create the observation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load the data\n",
    "from scarlet2.utils import import_scarlet_test_data\n",
    "import_scarlet_test_data()\n",
    "from scarlet_test_data import data_path\n",
    "\n",
    "file = jnp.load(os.path.join(data_path, \"hsc_cosmos_35.npz\"))\n",
    "data = jnp.asarray(file[\"images\"])\n",
    "channels = list(file['filters'])\n",
    "centers = jnp.array([(src['y'], src['x']) for src in file[\"catalog\"]])\n",
    "weights = jnp.asarray(1/file[\"variance\"])\n",
    "psf = jnp.asarray(file[\"psfs\"])\n",
    "\n",
    "# create the observation\n",
    "model_psf = GaussianPSF(0.7)\n",
    "model_frame = Frame(Box(data.shape), psf=model_psf, channels=channels)\n",
    "obs = Observation(data,\n",
    "                  weights,\n",
    "                  psf=ArrayPSF(psf),\n",
    "                  channels=channels,\n",
    "                  ).match(model_frame)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with Scene(model_frame) as scene:\n",
    "    for i, center in enumerate(centers):\n",
    "        if i == 0: # we know source 0 is a star\n",
    "            spectrum = init.pixel_spectrum(obs, center)\n",
    "            PointSource(center, spectrum)\n",
    "        else:\n",
    "            try:\n",
    "                spectrum, morph = init.from_gaussian_moments(obs, center, min_corr=0.99)\n",
    "            except ValueError:\n",
    "                spectrum = init.pixel_spectrum(obs, center)\n",
    "                morph = init.compact_morphology()\n",
    "\n",
    "            Source(center, spectrum, morph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Neural Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the model you wish to use\n",
    "from galaxygrad import HSC_ScoreNet32, HSC_ScoreNet64\n",
    "from scarlet2.nn import ScorePrior\n",
    "\n",
    "# instantiate the prior class\n",
    "temp = 1e-2 # values in the range of [1e-3, 1e-1] produce good results\n",
    "prior32 = ScorePrior(HSC_ScoreNet32, (32,32), t=temp)\n",
    "prior64 = ScorePrior(HSC_ScoreNet64, (64,64), t=temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prior model itself is in the form of a score-based diffusion model, which matches the score function, i.e. the gradient of the log-likelihood of the training data with respect to the parameters. For an image-based parameterization, the free parameters are the pixels, which means the gradient has the same shape as the image. `galaxygrad` provides several pre-trained models, here we use a prior that was trained on deblended isolate source in HSC data, with the shapes of 32x32 or 64x64, respectively. These sizes denote the maximum image size for which the prior is trained.\n",
    "\n",
    "We import `ScorePrior` to use with our prior. It automatically zero-pads any smaller image array up to the specified size and provides a custom gradient path that calls the underlying score model during optimization or HMC sampling. The `temp` argument refers to a fixed temperature for the diffusion process. For speed, we run a single diffusion step with the given temperature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Define Parameters with Prior\n",
    "\n",
    "We use the same fitting routine as in the Quickstart guide, but replace `contraints.positive` with `prior=prior` in the Parameter containing the source morphologies. It is also useful to reduce the step size for the morphology updates because large jumps can lead to unstable prior gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from numpyro.distributions import constraints\n",
    "spec_step = partial(relative_step, factor=0.01)\n",
    "morph_step = partial(relative_step, factor=1e-3)\n",
    "\n",
    "parameters = scene.make_parameters()\n",
    "for i in range(len(scene.sources)):\n",
    "    parameters += Parameter(scene.sources[i].spectrum.data,\n",
    "                            name=f\"spectrum:{i}\",\n",
    "                            constraint=constraints.positive,\n",
    "                            stepsize=spec_step)\n",
    "    if i == 0:\n",
    "        parameters += Parameter(scene.sources[i].center,\n",
    "                                name=f\"center:{i}\",\n",
    "                                stepsize=0.1)\n",
    "    else:\n",
    "        # chose a prior of suitable size\n",
    "        prior = prior32 if max(scene.sources[i].morphology.data.shape) <= 32 else prior64\n",
    "        parameters += Parameter(scene.sources[i].morphology.data,\n",
    "                                name=f\"morph:{i}\",\n",
    "                                prior=prior, # attach the prior here\n",
    "                                stepsize=morph_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the use of a `prior` is incompatible with the use of a `constraint`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We again perform the fitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxiter = 1000\n",
    "scene.set_spectra_to_match(obs, parameters)\n",
    "scene_ = scene.fit(obs, parameters, max_iter=maxiter, e_rel=1e-3, progress_bar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The fit converges about half-way through, but reaches values a little bit worse than for morphologies with the positivity constraint in the quickstart guide."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm = plot.AsinhAutomaticNorm(obs)\n",
    "plot.scene(scene_,\n",
    "           obs,\n",
    "           norm=norm,\n",
    "           show_model=True,\n",
    "           show_rendered=True,\n",
    "           show_observed=True,\n",
    "           show_residual=True,\n",
    "           add_boxes=True,\n",
    "           )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot.sources(scene_,\n",
    "             norm=norm,\n",
    "             observation=obs,\n",
    "             show_model=True,\n",
    "             show_rendered=True,\n",
    "             show_observed=True,\n",
    "             show_spectrum=True,\n",
    "             add_markers=False,\n",
    "             add_boxes=True,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results for most of the galaxies look very reasonable now, in particular for the fainter ones. They remain compact and not affected by noise. Source #1 and #2 use the larger prior (64x64 pixels), which is not quite as robust as the one for 32x32 pixel images, so we see artifacts from pixel noise and neighboring objects. This prior has not been trained (yet) on as many galaxies and is therefore still somewhat weak. An update will fix this soon."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
